{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Deploying on AWS SageMaker for scheduled Batch Transform.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXaAE_nqVWs8"
      },
      "source": [
        "# Deploying on AWS SageMaker for scheduled Batch Transform\n",
        "\n",
        "Notebook version\n",
        "\n",
        "by [Daniel Marostica](https://www.linkedin.com/in/danielmarostica/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw2D8XXPU3rW"
      },
      "source": [
        "import os\n",
        "import sys\n",
        "\n",
        "import boto3, sagemaker\n",
        "\n",
        "from sagemaker.sklearn.processing import SKLearnProcessor\n",
        "from sagemaker.sklearn.estimator import SKLearn\n",
        "from sagemaker.processing import ProcessingInput, ProcessingOutput\n",
        "from sagemaker.sklearn.model import SKLearnModel"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm9Ql4IcVery"
      },
      "source": [
        "## Get role with sagemaker, and S3 permissions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQiWWH-MVMlS"
      },
      "source": [
        "iam = boto3.client('iam')\n",
        "role = iam.get_role(RoleName='datascience-sagemaker-s3')['Role']['Arn']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aPZYFdoSVkwM"
      },
      "source": [
        "## Start session\n",
        "\n",
        "You must have your credentials file at /home/your.name/.aws/ correctly set with CLI keys and tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Cr0zlEHVOR9"
      },
      "source": [
        "sagemaker_session = sagemaker.Session()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dg0h5_QVQBc"
      },
      "source": [
        "bucket = sagemaker_session.default_bucket() # creates a bucket based on your region and account ID\n",
        "prefix = \"titanic_example\" # folder name"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cDnWIb2ZWLTh"
      },
      "source": [
        "## Upload csv to S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uIudyF0iWGH_",
        "outputId": "8edbb3af-be18-4e65-fbdf-4a3fe6e3ad7a"
      },
      "source": [
        "def upload(sagemaker_session, bucket, prefix, file_path):\n",
        "    raw_data = sagemaker_session.upload_data(\n",
        "        path=\"{}\".format(file_path),\n",
        "        bucket=bucket,\n",
        "        key_prefix=\"{}\".format(prefix))\n",
        "    print('Data has been stored in the following bucket:', bucket)\n",
        "    return raw_data\n",
        "\n",
        "s3_data_uri = upload(sagemaker_session, bucket, prefix, file_path='data/data.csv')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data has been stored in the following bucket: sagemaker-us-east-1-296025910508\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PNVPpbEZWs3d"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELEFpsnPW1xc"
      },
      "source": [
        "### Define the instance to be created"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jo_2oPHUVSxc"
      },
      "source": [
        "sklearn_processor = SKLearnProcessor(framework_version='0.23-1',\n",
        "                                    role=role,\n",
        "                                    instance_type='ml.t3.medium',\n",
        "                                    instance_count=1,\n",
        "                                    base_job_name='sm-preprocessing')"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAZ3ys12W4SD"
      },
      "source": [
        "### Start the job\n",
        "\n",
        "You can check its state at AWS's web interface under SageMaker > Processing Jobs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KbE6o3GCWyq9",
        "outputId": "56ff526a-929e-4dd3-99e5-05f635e41940"
      },
      "source": [
        "sklearn_processor.run(code='modules/preprocessing.py',\n",
        "                    inputs=[ProcessingInput(\n",
        "                            source=s3_data_uri,\n",
        "                            destination='/opt/ml/processing/input')],\n",
        "                    outputs=[ProcessingOutput(output_name='train_data',\n",
        "                                                source='/opt/ml/processing/train'),\n",
        "                            ProcessingOutput(output_name='test_data',\n",
        "                                                source='/opt/ml/processing/test')],\n",
        "                    arguments=['--train-test-split-ratio', '0.2'])\n",
        "\n",
        "preprocessing_job_description = sklearn_processor.jobs[-1].describe() # save the name of the processing job"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Job Name:  sm-preprocessing-2021-11-30-19-47-11-855\n",
            "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/titanic_example/data.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/sm-preprocessing-2021-11-30-19-47-11-855/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
            "Outputs:  [{'OutputName': 'train_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/sm-preprocessing-2021-11-30-19-47-11-855/output/train_data', 'LocalPath': '/opt/ml/processing/train', 'S3UploadMode': 'EndOfJob'}}, {'OutputName': 'test_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/sm-preprocessing-2021-11-30-19-47-11-855/output/test_data', 'LocalPath': '/opt/ml/processing/test', 'S3UploadMode': 'EndOfJob'}}]\n",
            "..........................................................\n",
            "\u001b[34mReceived arguments Namespace(inference='false', input_folder='/opt/ml/processing/input', train_test_split_ratio=0.2)\u001b[0m\n",
            "\u001b[34mReading input data from /opt/ml/processing/input/data.csv\u001b[0m\n",
            "\u001b[34mSplitting data into train and test sets with ratio 0.2\u001b[0m\n",
            "\u001b[34mRunning preprocessing and feature engineering transformations\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlUByT0EXQUX"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ysg1Q61XTw_"
      },
      "source": [
        "sklearn = SKLearn(\n",
        "    entry_point='modules/model.py',\n",
        "    framework_version='0.23-1',\n",
        "    instance_type='ml.m5.large',\n",
        "    role=role,\n",
        "    sagemaker_session=sagemaker_session,\n",
        "    hyperparameters={\"max_leaf_nodes\": 30}, # you can pass hyperparameters to the algorithm\n",
        "    base_job_name='sm-training')"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oEMN0JFHVVL8",
        "outputId": "f04131a9-3063-42e7-ad34-ecfa2281e975"
      },
      "source": [
        "train_file = os.path.join('s3://', bucket, preprocessing_job_description['ProcessingJobName'], 'output', 'train_data', 'train.csv')\n",
        "test_file = os.path.join('s3://', bucket, preprocessing_job_description['ProcessingJobName'], 'output', 'test_data', 'test.csv')\n",
        "\n",
        "sklearn.fit({'train': train_file, 'test': test_file})\n",
        "\n",
        "training_job_name = sklearn._current_job_name # save the name of the training job"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2021-11-30 20:11:30 Starting - Starting the training job...\n",
            "2021-11-30 20:12:01 Starting - Launching requested ML instancesProfilerReport-1638303088: InProgress\n",
            "......\n",
            "2021-11-30 20:13:02 Starting - Preparing the instances for training......\n",
            "2021-11-30 20:14:22 Downloading - Downloading input data...\n",
            "2021-11-30 20:14:47 Training - Downloading the training image..\u001b[34m2021-11-30 20:15:07,998 sagemaker-containers INFO     Imported framework sagemaker_sklearn_container.training\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:08,001 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:08,012 sagemaker_sklearn_container.training INFO     Invoking user training script.\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:15,413 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:15,425 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:15,438 sagemaker-training-toolkit INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:15,447 sagemaker-training-toolkit INFO     Invoking user script\u001b[0m\n",
            "\u001b[34mTraining Env:\u001b[0m\n",
            "\u001b[34m{\n",
            "    \"additional_framework_parameters\": {},\n",
            "    \"channel_input_dirs\": {\n",
            "        \"test\": \"/opt/ml/input/data/test\",\n",
            "        \"train\": \"/opt/ml/input/data/train\"\n",
            "    },\n",
            "    \"current_host\": \"algo-1\",\n",
            "    \"framework_module\": \"sagemaker_sklearn_container.training:main\",\n",
            "    \"hosts\": [\n",
            "        \"algo-1\"\n",
            "    ],\n",
            "    \"hyperparameters\": {\n",
            "        \"max_leaf_nodes\": 30\n",
            "    },\n",
            "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
            "    \"input_data_config\": {\n",
            "        \"test\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        },\n",
            "        \"train\": {\n",
            "            \"TrainingInputMode\": \"File\",\n",
            "            \"S3DistributionType\": \"FullyReplicated\",\n",
            "            \"RecordWrapperType\": \"None\"\n",
            "        }\n",
            "    },\n",
            "    \"input_dir\": \"/opt/ml/input\",\n",
            "    \"is_master\": true,\n",
            "    \"job_name\": \"sm-training-2021-11-30-20-11-28-217\",\n",
            "    \"log_level\": 20,\n",
            "    \"master_hostname\": \"algo-1\",\n",
            "    \"model_dir\": \"/opt/ml/model\",\n",
            "    \"module_dir\": \"s3://sagemaker-us-east-1-296025910508/sm-training-2021-11-30-20-11-28-217/source/sourcedir.tar.gz\",\n",
            "    \"module_name\": \"model\",\n",
            "    \"network_interface_name\": \"eth0\",\n",
            "    \"num_cpus\": 2,\n",
            "    \"num_gpus\": 0,\n",
            "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
            "    \"output_dir\": \"/opt/ml/output\",\n",
            "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
            "    \"resource_config\": {\n",
            "        \"current_host\": \"algo-1\",\n",
            "        \"hosts\": [\n",
            "            \"algo-1\"\n",
            "        ],\n",
            "        \"network_interface_name\": \"eth0\"\n",
            "    },\n",
            "    \"user_entry_point\": \"model.py\"\u001b[0m\n",
            "\u001b[34m}\u001b[0m\n",
            "\u001b[34mEnvironment variables:\u001b[0m\n",
            "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
            "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
            "\u001b[34mSM_HPS={\"max_leaf_nodes\":30}\u001b[0m\n",
            "\u001b[34mSM_USER_ENTRY_POINT=model.py\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
            "\u001b[34mSM_RESOURCE_CONFIG={\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
            "\u001b[34mSM_INPUT_DATA_CONFIG={\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
            "\u001b[34mSM_CHANNELS=[\"test\",\"train\"]\u001b[0m\n",
            "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
            "\u001b[34mSM_MODULE_NAME=model\u001b[0m\n",
            "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
            "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_sklearn_container.training:main\u001b[0m\n",
            "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
            "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
            "\u001b[34mSM_NUM_CPUS=2\u001b[0m\n",
            "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
            "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
            "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-296025910508/sm-training-2021-11-30-20-11-28-217/source/sourcedir.tar.gz\u001b[0m\n",
            "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"test\":\"/opt/ml/input/data/test\",\"train\":\"/opt/ml/input/data/train\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_sklearn_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"max_leaf_nodes\":30},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"test\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"},\"train\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sm-training-2021-11-30-20-11-28-217\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-296025910508/sm-training-2021-11-30-20-11-28-217/source/sourcedir.tar.gz\",\"module_name\":\"model\",\"network_interface_name\":\"eth0\",\"num_cpus\":2,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_host\":\"algo-1\",\"hosts\":[\"algo-1\"],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"model.py\"}\u001b[0m\n",
            "\u001b[34mSM_USER_ARGS=[\"--max_leaf_nodes\",\"30\"]\u001b[0m\n",
            "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TEST=/opt/ml/input/data/test\u001b[0m\n",
            "\u001b[34mSM_CHANNEL_TRAIN=/opt/ml/input/data/train\u001b[0m\n",
            "\u001b[34mSM_HP_MAX_LEAF_NODES=30\u001b[0m\n",
            "\u001b[34mPYTHONPATH=/opt/ml/code:/miniconda3/bin:/miniconda3/lib/python37.zip:/miniconda3/lib/python3.7:/miniconda3/lib/python3.7/lib-dynload:/miniconda3/lib/python3.7/site-packages\u001b[0m\n",
            "\u001b[34mInvoking script with the following command:\u001b[0m\n",
            "\u001b[34m/miniconda3/bin/python model.py --max_leaf_nodes 30\u001b[0m\n",
            "\u001b[34mModel saved at /opt/ml/model/model.joblib\u001b[0m\n",
            "\u001b[34m2021-11-30 20:15:16,903 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
            "\n",
            "2021-11-30 20:15:26 Uploading - Uploading generated training model\n",
            "2021-11-30 20:15:26 Completed - Training job completed\n",
            "Training seconds: 69\n",
            "Billable seconds: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_UwVIlDer-Q"
      },
      "source": [
        "## Load model for inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deqdME-9ehPg"
      },
      "source": [
        "model_artifact = os.path.join('s3://', bucket, training_job_name, 'output', 'model.tar.gz') # fancy name for pickle\n",
        "\n",
        "model = SKLearnModel(model_data=model_artifact,\n",
        "                     role=role,\n",
        "                     framework_version='0.23-1',\n",
        "                     entry_point='modules/model.py')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Am2be1Ooe95H"
      },
      "source": [
        "### Load and transform data for inference\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjHkSA9umJF_",
        "outputId": "1bdf6b6b-a9a7-4049-9b54-488deaa1442f"
      },
      "source": [
        "data = os.path.join('s3://', bucket, 'titanic_example', 'data.csv')\n",
        "\n",
        "sklearn_processor = SKLearnProcessor(framework_version='0.23-1',\n",
        "                                    role=role,\n",
        "                                    instance_type='ml.t3.medium',\n",
        "                                    instance_count=1)\n",
        "\n",
        "sklearn_processor.run(code='modules/preprocessing.py',\n",
        "                    inputs=[ProcessingInput(\n",
        "                            source=data,\n",
        "                            destination='/opt/ml/processing/input')],\n",
        "                    outputs=[ProcessingOutput(output_name='processed_data',\n",
        "                                                source='/opt/ml/processing/data')],\n",
        "                    arguments=['--inference', 'true']) # this will prevent train/test split\n",
        "\n",
        "preprocessing_job_description = sklearn_processor.jobs[-1].describe() \n",
        "processed_data = os.path.join('s3://', bucket, preprocessing_job_description['ProcessingJobName'], 'output', 'processed_data', 'data.csv') # retrieve the dumped file"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Job Name:  sagemaker-scikit-learn-2021-11-30-20-45-53-997\n",
            "Inputs:  [{'InputName': 'input-1', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/titanic_example/data.csv', 'LocalPath': '/opt/ml/processing/input', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}, {'InputName': 'code', 'AppManaged': False, 'S3Input': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/sagemaker-scikit-learn-2021-11-30-20-45-53-997/input/code/preprocessing.py', 'LocalPath': '/opt/ml/processing/input/code', 'S3DataType': 'S3Prefix', 'S3InputMode': 'File', 'S3DataDistributionType': 'FullyReplicated', 'S3CompressionType': 'None'}}]\n",
            "Outputs:  [{'OutputName': 'processed_data', 'AppManaged': False, 'S3Output': {'S3Uri': 's3://sagemaker-us-east-1-296025910508/sagemaker-scikit-learn-2021-11-30-20-45-53-997/output/processed_data', 'LocalPath': '/opt/ml/processing/data', 'S3UploadMode': 'EndOfJob'}}]\n",
            ".............................................................\u001b[34mReceived arguments Namespace(inference='true', input_folder='/opt/ml/processing/input', train_test_split_ratio=0.3)\u001b[0m\n",
            "\u001b[34mReading input data from /opt/ml/processing/input/data.csv\u001b[0m\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhzSx2zLmY2i"
      },
      "source": [
        "## Prediction/Inference\n",
        "\n",
        "The transformer already knows that, by default, the first column is the target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lti9iu_QmRgq"
      },
      "source": [
        "Finally, do the batch transform with the processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rw6kd0pA2cM"
      },
      "source": [
        "output_path = 's3://{}/{}/titanic_results'.format(bucket, prefix)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D_XhXaRpfCW2",
        "outputId": "731318d9-f99f-416a-a12d-6caba263564f"
      },
      "source": [
        "transformer = model.transformer(\n",
        "    instance_count=1, \n",
        "    instance_type='ml.m4.xlarge', \n",
        "    assemble_with='Line', \n",
        "    accept='text/csv',\n",
        "    output_path=os.path.join(output_path, 'data.csv.out'))       \n",
        "\n",
        "transformer.transform(data=processed_data, content_type='text/csv')                 "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "..............................\n",
            "\u001b[34m2021-11-30 22:49:33,180 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:33,182 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:33,183 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
            "\u001b[34mworker_processes auto;\u001b[0m\n",
            "\u001b[34mdaemon off;\u001b[0m\n",
            "\u001b[34mpid /tmp/nginx.pid;\u001b[0m\n",
            "\u001b[34merror_log  /dev/stderr;\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,180 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,182 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,183 INFO - sagemaker-containers - nginx config: \u001b[0m\n",
            "\u001b[35mworker_processes auto;\u001b[0m\n",
            "\u001b[35mdaemon off;\u001b[0m\n",
            "\u001b[35mpid /tmp/nginx.pid;\u001b[0m\n",
            "\u001b[35merror_log  /dev/stderr;\u001b[0m\n",
            "\u001b[34mworker_rlimit_nofile 4096;\u001b[0m\n",
            "\u001b[34mevents {\n",
            "  worker_connections 2048;\u001b[0m\n",
            "\u001b[34m}\u001b[0m\n",
            "\u001b[34mhttp {\n",
            "  include /etc/nginx/mime.types;\n",
            "  default_type application/octet-stream;\n",
            "  access_log /dev/stdout combined;\n",
            "  upstream gunicorn {\n",
            "    server unix:/tmp/gunicorn.sock;\n",
            "  }\n",
            "  server {\n",
            "    listen 8080 deferred;\n",
            "    client_max_body_size 0;\n",
            "    keepalive_timeout 3;\n",
            "    location ~ ^/(ping|invocations|execution-parameters) {\n",
            "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
            "      proxy_set_header Host $http_host;\n",
            "      proxy_redirect off;\n",
            "      proxy_read_timeout 60s;\n",
            "      proxy_pass http://gunicorn;\n",
            "    }\n",
            "    location / {\n",
            "      return 404 \"{}\";\n",
            "    }\n",
            "  }\u001b[0m\n",
            "\u001b[34m}\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Module model does not provide a setup.py. \u001b[0m\n",
            "\u001b[34mGenerating setup.py\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
            "\u001b[34m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
            "\u001b[34mProcessing /opt/ml/code\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "\u001b[35mworker_rlimit_nofile 4096;\u001b[0m\n",
            "\u001b[35mevents {\n",
            "  worker_connections 2048;\u001b[0m\n",
            "\u001b[35m}\u001b[0m\n",
            "\u001b[35mhttp {\n",
            "  include /etc/nginx/mime.types;\n",
            "  default_type application/octet-stream;\n",
            "  access_log /dev/stdout combined;\n",
            "  upstream gunicorn {\n",
            "    server unix:/tmp/gunicorn.sock;\n",
            "  }\n",
            "  server {\n",
            "    listen 8080 deferred;\n",
            "    client_max_body_size 0;\n",
            "    keepalive_timeout 3;\n",
            "    location ~ ^/(ping|invocations|execution-parameters) {\n",
            "      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;\n",
            "      proxy_set_header Host $http_host;\n",
            "      proxy_redirect off;\n",
            "      proxy_read_timeout 60s;\n",
            "      proxy_pass http://gunicorn;\n",
            "    }\n",
            "    location / {\n",
            "      return 404 \"{}\";\n",
            "    }\n",
            "  }\u001b[0m\n",
            "\u001b[35m}\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Module model does not provide a setup.py. \u001b[0m\n",
            "\u001b[35mGenerating setup.py\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Generating setup.cfg\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Generating MANIFEST.in\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:33,319 INFO - sagemaker-containers - Installing module with the following command:\u001b[0m\n",
            "\u001b[35m/miniconda3/bin/python3 -m pip install . \u001b[0m\n",
            "\u001b[35mProcessing /opt/ml/code\n",
            "  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "\u001b[34mBuilding wheels for collected packages: model\n",
            "  Building wheel for model (setup.py): started\n",
            "  Building wheel for model (setup.py): finished with status 'done'\n",
            "  Created wheel for model: filename=model-1.0.0-py2.py3-none-any.whl size=4195 sha256=9a23ddec5687a9fbb7f8bde0e81157e11ee288273d054c4f97e7964463dff7af\n",
            "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-38c0mh4g/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
            "\u001b[34mSuccessfully built model\u001b[0m\n",
            "\u001b[34mInstalling collected packages: model\u001b[0m\n",
            "\u001b[34mSuccessfully installed model-1.0.0\u001b[0m\n",
            "\u001b[35mBuilding wheels for collected packages: model\n",
            "  Building wheel for model (setup.py): started\n",
            "  Building wheel for model (setup.py): finished with status 'done'\n",
            "  Created wheel for model: filename=model-1.0.0-py2.py3-none-any.whl size=4195 sha256=9a23ddec5687a9fbb7f8bde0e81157e11ee288273d054c4f97e7964463dff7af\n",
            "  Stored in directory: /home/model-server/tmp/pip-ephem-wheel-cache-38c0mh4g/wheels/3e/0f/51/2f1df833dd0412c1bc2f5ee56baac195b5be563353d111dca6\u001b[0m\n",
            "\u001b[35mSuccessfully built model\u001b[0m\n",
            "\u001b[35mInstalling collected packages: model\u001b[0m\n",
            "\u001b[35mSuccessfully installed model-1.0.0\u001b[0m\n",
            "\u001b[34mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[35mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n",
            "\u001b[34mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\u001b[0m\n",
            "\u001b[34mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "\u001b[35mWARNING: You are using pip version 21.2.4; however, version 21.3.1 is available.\u001b[0m\n",
            "\u001b[35mYou should consider upgrading via the '/miniconda3/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [37] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [37] [INFO] Using worker: gevent\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
            "\u001b[34m[2021-11-30 22:49:36 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [37] [INFO] Starting gunicorn 20.0.4\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [37] [INFO] Listening at: unix:/tmp/gunicorn.sock (37)\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [37] [INFO] Using worker: gevent\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [40] [INFO] Booting worker with pid: 40\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [41] [INFO] Booting worker with pid: 41\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [42] [INFO] Booting worker with pid: 42\u001b[0m\n",
            "\u001b[35m[2021-11-30 22:49:36 +0000] [43] [INFO] Booting worker with pid: 43\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:39,513 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:39,513 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m169.254.255.130 - - [30/Nov/2021:22:49:40 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
            "\u001b[34m2021-11-30 22:49:40,222 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[34m169.254.255.130 - - [30/Nov/2021:22:49:40 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
            "\u001b[35m169.254.255.130 - - [30/Nov/2021:22:49:40 +0000] \"GET /ping HTTP/1.1\" 200 0 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
            "\u001b[35m2021-11-30 22:49:40,222 INFO - sagemaker-containers - No GPUs detected (normal if no gpus installed)\u001b[0m\n",
            "\u001b[35m169.254.255.130 - - [30/Nov/2021:22:49:40 +0000] \"GET /execution-parameters HTTP/1.1\" 404 232 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
            "\u001b[34m169.254.255.130 - - [30/Nov/2021:22:49:41 +0000] \"POST /invocations HTTP/1.1\" 200 3564 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
            "\u001b[35m169.254.255.130 - - [30/Nov/2021:22:49:41 +0000] \"POST /invocations HTTP/1.1\" 200 3564 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
            "\u001b[32m2021-11-30T22:49:40.856:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WgOqRuO8At0w"
      },
      "source": [
        "Bring a copy of the results from S3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ip_xpwYnDRDy",
        "outputId": "9a2c29f6-288b-4297-ab6d-08a7d2641496"
      },
      "source": [
        "os.path.join(output_path, 'data.csv.out')"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'s3://sagemaker-us-east-1-296025910508/titanic_example/titanic_results/data.csv.out'"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x78VaILT_Tdd",
        "outputId": "419a71c3-5ddb-45b5-b0ed-bcfb03755a34"
      },
      "source": [
        "!aws s3 cp 's3://sagemaker-us-east-1-296025910508/titanic_example/titanic_results/data.csv.out' ./"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Completed 3.5 KiB/3.5 KiB (2.5 KiB/s) with 1 file(s) remaining\rdownload: s3://sagemaker-us-east-1-296025910508/titanic_example/titanic_results/data.csv.out to ./data.csv.out\r\n"
          ]
        }
      ]
    }
  ]
}